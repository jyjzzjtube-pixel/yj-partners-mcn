# -*- coding: utf-8 -*-
"""
YJ MCN ìë™í™” ëŒ€ì‹œë³´ë“œ â€” Flask ë°±ì—”ë“œ
=====================================
ê¸°ì¡´ affiliate_system ëª¨ë“ˆì„ REST APIë¡œ ë˜í•‘.
SSEë¡œ íŒŒì´í”„ë¼ì¸ ì§„í–‰ìƒí™© ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°.

ì‹¤í–‰: python yj-partners-mcn/mcn_server.py
"""
import json
import sys
import time
import uuid
import threading
from pathlib import Path
from queue import Queue
from datetime import datetime

from flask import Flask, request, jsonify, Response, send_file, send_from_directory
from flask_cors import CORS
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_DIR = Path(__file__).parent.parent  # franchise-db/
sys.path.insert(0, str(PROJECT_DIR))
load_dotenv(PROJECT_DIR / '.env', override=True)

from affiliate_system.config import (
    GEMINI_API_KEY, ANTHROPIC_API_KEY, PEXELS_API_KEY,
    PIXABAY_API_KEY, UNSPLASH_ACCESS_KEY, RENDER_OUTPUT_DIR, WORK_DIR,
)
from affiliate_system.models import Platform, PLATFORM_PRESETS

# â”€â”€ ì»¤ë§¨ë“œì„¼í„° AI ì„œë¹„ìŠ¤ ì—°ë™ â”€â”€
sys.path.insert(0, str(PROJECT_DIR))
from command_center.config import OPENAI_API_KEY, OLLAMA_BASE_URL, OLLAMA_MODEL, AI_PROVIDERS
from command_center.services.ai_service import AIService

ai_service = AIService()

# â”€â”€ Flask ì•± ì„¤ì • â”€â”€
app = Flask(__name__, static_folder=str(Path(__file__).parent))
CORS(app)

# â”€â”€ Job ì €ì¥ì†Œ & ìº í˜ì¸ íˆìŠ¤í† ë¦¬ â”€â”€
jobs = {}  # job_id -> {status, step, progress, results, events, error}
campaign_history = []  # ìº í˜ì¸ ì´ë ¥ (ìµœê·¼ 50ê°œ)

# â”€â”€ ìº í˜ì¸ DB (SQLite) â”€â”€
import sqlite3
CAMPAIGN_DB = str(PROJECT_DIR / "mcn_campaigns.db")

def _init_campaign_db():
    """ìº í˜ì¸ íˆìŠ¤í† ë¦¬ DB ì´ˆê¸°í™”"""
    conn = sqlite3.connect(CAMPAIGN_DB)
    conn.execute("""CREATE TABLE IF NOT EXISTS campaigns (
        id TEXT PRIMARY KEY,
        topic TEXT, brand TEXT, platforms TEXT,
        ai_provider TEXT, cost_usd REAL DEFAULT 0,
        status TEXT DEFAULT 'pending',
        results TEXT,
        created_at TEXT DEFAULT CURRENT_TIMESTAMP
    )""")
    conn.commit()
    conn.close()

_init_campaign_db()

# â”€â”€ ë¸Œëœë“œ ì„¤ì • â”€â”€
BRANDS = {
    "ì˜¤ë ˆë…¸ì¹´ì¸ ": {
        "name": "ì˜¤ë ˆë…¸ì¹´ì¸ ",
        "type": "Japanese Tonkatsu Franchise",
        "emoji": "ğŸ±",
        "platforms": ["youtube", "naver_blog", "instagram"],
        "campaigns": 12,
    },
    "ë¬´ì‚¬ì§¬ë½•": {
        "name": "ë¬´ì‚¬ì§¬ë½•",
        "type": "Chinese Jjamppong Franchise",
        "emoji": "ğŸœ",
        "platforms": ["youtube", "naver_blog", "instagram"],
        "campaigns": 8,
    },
    "ë¸Œë¦¿ì§€ì›": {
        "name": "ë¸Œë¦¿ì§€ì›",
        "type": "Franchise Consulting (BRIDGE ONE)",
        "emoji": "ğŸ’¼",
        "platforms": ["youtube", "naver_blog", "instagram", "coupang"],
        "campaigns": 15,
    },
}

PLATFORM_MAP = {
    "youtube": Platform.YOUTUBE,
    "instagram": Platform.INSTAGRAM,
    "naver_blog": Platform.NAVER_BLOG,
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ìœ í‹¸ë¦¬í‹°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _to_relative_path(abs_path) -> str:
    """ì ˆëŒ€ ê²½ë¡œë¥¼ PROJECT_DIR ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (í”„ë¡ íŠ¸ì—”ë“œ íŒŒì¼ ì„œë¹™ìš©)."""
    if not abs_path:
        return ""
    p = Path(str(abs_path))
    try:
        return str(p.relative_to(PROJECT_DIR)).replace("\\", "/")
    except ValueError:
        # PROJECT_DIR ë°–ì˜ ê²½ë¡œë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return str(p).replace("\\", "/")


def serialize_results(results: dict) -> dict:
    """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜."""
    out = {"platforms": {}, "upload_results": {}}
    for p_name, p_data in results.get("platforms", {}).items():
        out["platforms"][p_name] = {
            "video": _to_relative_path(p_data.get("video")) or None,
            "thumbnail": _to_relative_path(p_data.get("thumbnail")) or None,
            "content": p_data.get("content", {}),
        }
    out["upload_results"] = results.get("upload_results", {})
    campaign = results.get("campaign")
    if campaign:
        out["campaign_id"] = campaign.id
        out["created_at"] = campaign.created_at.isoformat() if campaign.created_at else None
    return out


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WebPipeline â€” ë‹¨ê³„ë³„ SSE ì´ë²¤íŠ¸ ë°œìƒ ë˜í¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class WebPipeline:
    """ContentPipelineì„ ë‹¨ê³„ë³„ë¡œ ì‹¤í–‰í•˜ë©° SSE ì´ë²¤íŠ¸ë¥¼ ë°œìƒì‹œí‚¨ë‹¤."""

    def __init__(self, events_queue: Queue):
        self._q = events_queue

    def _emit(self, step: int, name: str, status: str, detail: str = ""):
        self._q.put({
            "type": "step",
            "step": step,
            "name": name,
            "status": status,
            "detail": detail,
            "timestamp": datetime.now().isoformat(),
        })

    def run(self, topic: str, platforms: list, brand: str, persona: str,
            auto_upload: bool, drive_archive: bool = True) -> dict:
        from affiliate_system.pipeline import ContentPipeline

        pipeline = ContentPipeline()
        platform_enums = [PLATFORM_MAP[p] for p in platforms if p in PLATFORM_MAP]
        if not platform_enums:
            platform_enums = list(PLATFORM_MAP.values())

        results = {"platforms": {}, "upload_results": {}}

        # Step 1: ìƒí’ˆ ì •ë³´
        self._emit(1, "product_info", "running", "ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        try:
            product = pipeline._prepare_product(topic)
            self._emit(1, "product_info", "complete", f"ìƒí’ˆ: {product.title}")
        except Exception as e:
            self._emit(1, "product_info", "error", str(e))
            raise

        # Step 2: AI ì½˜í…ì¸  ìƒì„±
        self._emit(2, "ai_content", "running", f"{len(platform_enums)}ê°œ í”Œë«í¼ AI ì½˜í…ì¸  ìƒì„± ì¤‘...")
        try:
            platform_contents = pipeline._generate_contents(product, platform_enums, persona, brand)
            detail_parts = []
            for p_name, content in platform_contents.items():
                narr = len(content.get("narration", []))
                tags = len(content.get("hashtags", []))
                detail_parts.append(f"{p_name}: ë‚˜ë ˆì´ì…˜ {narr}ì¥ë©´, íƒœê·¸ {tags}ê°œ")
            self._emit(2, "ai_content", "complete", " | ".join(detail_parts))
        except Exception as e:
            self._emit(2, "ai_content", "error", str(e))
            raise

        # Step 3: ë¯¸ë””ì–´ ìˆ˜ì§‘
        self._emit(3, "media", "running", "ë¬´ë£Œ ìŠ¤í†¡ ì´ë¯¸ì§€ ìˆ˜ì§‘ ì¤‘...")
        try:
            images = pipeline._collect_media(product)
            self._emit(3, "media", "complete", f"ì´ë¯¸ì§€ {len(images)}ê°œ ìˆ˜ì§‘")
        except Exception as e:
            self._emit(3, "media", "error", str(e))
            images = []

        # Step 4: ì¸ë„¤ì¼ ìƒì„±
        self._emit(4, "thumbnail", "running", "í”Œë«í¼ë³„ ì¸ë„¤ì¼ ìƒì„± ì¤‘...")
        try:
            campaign_id = uuid.uuid4().hex[:8]
            thumbnails = pipeline._generate_thumbnails(
                platform_enums, platform_contents, images, brand, campaign_id,
            )
            self._emit(4, "thumbnail", "complete", f"{len(thumbnails)}ê°œ ì¸ë„¤ì¼ ìƒì„±")
        except Exception as e:
            self._emit(4, "thumbnail", "error", str(e))
            thumbnails = {}

        # Step 5: ì˜ìƒ ë Œë”ë§
        self._emit(5, "video_render", "running", "ì˜ìƒ ë Œë”ë§ ì¤‘ (ì‹œê°„ ì†Œìš”)...")
        try:
            videos = pipeline._render_videos(
                platform_enums, platform_contents, images, brand, campaign_id,
            )
            rendered = [p for p, v in videos.items() if v]
            self._emit(5, "video_render", "complete", f"{len(rendered)}ê°œ ì˜ìƒ ë Œë”ë§ ì™„ë£Œ")
        except Exception as e:
            self._emit(5, "video_render", "error", str(e))
            videos = {}

        # ê²°ê³¼ ì¡°í•© (ì ˆëŒ€ ê²½ë¡œ â†’ ìƒëŒ€ ê²½ë¡œ ë³€í™˜)
        for p in platform_enums:
            p_name = p.value
            results["platforms"][p_name] = {
                "video": _to_relative_path(videos.get(p_name)) or None,
                "thumbnail": _to_relative_path(thumbnails.get(p_name)) or None,
                "content": platform_contents.get(p_name, {}),
            }

        # Step 6: ì†Œì…œ ë¯¸ë””ì–´ ì—…ë¡œë“œ
        if auto_upload:
            self._emit(6, "upload", "running", "3í”Œë«í¼ ì—…ë¡œë“œ ì¤‘...")
            try:
                from affiliate_system.models import Campaign, AIContent, CampaignStatus
                campaign_obj = Campaign(
                    id=campaign_id, product=product,
                    ai_content=AIContent(platform_contents=platform_contents),
                    status=CampaignStatus.UPLOADING,
                    target_platforms=platform_enums,
                    platform_videos=videos, platform_thumbnails=thumbnails,
                    created_at=datetime.now(),
                )
                upload_results = pipeline._upload_all(campaign_obj)
                results["upload_results"] = upload_results
                self._emit(6, "upload", "complete", "ì—…ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                self._emit(6, "upload", "error", str(e))
        else:
            self._emit(6, "upload", "skipped", "ì—…ë¡œë“œ ê±´ë„ˆëœ€ (ìˆ˜ë™ ëª¨ë“œ)")

        # Step 7: Google Drive ìë™ ì•„ì¹´ì´ë¹™
        if drive_archive:
            self._emit(7, "drive_archive", "running", "Google Drive í´ë” ìƒì„± ë° ì—…ë¡œë“œ ì¤‘...")
            try:
                from affiliate_system.drive_manager import DriveArchiver
                from affiliate_system.models import Campaign, AIContent, CampaignStatus

                # Campaign ê°ì²´ ìƒì„±
                campaign_obj = Campaign(
                    id=campaign_id, product=product,
                    ai_content=AIContent(platform_contents=platform_contents),
                    status=CampaignStatus.COMPLETE,
                    target_platforms=platform_enums,
                    platform_videos=videos, platform_thumbnails=thumbnails,
                    created_at=datetime.now(),
                )

                # ì—…ë¡œë“œí•  íŒŒì¼ ë¶„ë¥˜
                drive_files = {"images": [], "renders": [], "audio": [], "logs": []}

                # ë Œë”ë§ ê²°ê³¼ (ì˜ìƒ + ì¸ë„¤ì¼)
                for p_name, v_path in videos.items():
                    if v_path and Path(str(v_path)).exists():
                        drive_files["renders"].append(str(v_path))
                for p_name, t_path in thumbnails.items():
                    if t_path and Path(str(t_path)).exists():
                        drive_files["renders"].append(str(t_path))

                # ìˆ˜ì§‘ëœ ì´ë¯¸ì§€
                media_dir = WORK_DIR / "media_downloads"
                if media_dir.exists():
                    for img in sorted(media_dir.glob("*.*"))[-20:]:  # ìµœê·¼ 20ê°œ
                        if img.suffix.lower() in (".jpg", ".jpeg", ".png", ".webp"):
                            drive_files["images"].append(str(img))

                # TTS ì˜¤ë””ì˜¤ (ìµœê·¼ ìƒì„±ëœ tts_ í´ë”)
                for tts_dir in sorted(WORK_DIR.glob("tts_*"), reverse=True)[:1]:
                    if tts_dir.is_dir():
                        for audio_f in tts_dir.glob("*.mp3"):
                            drive_files["audio"].append(str(audio_f))

                total_files = sum(len(v) for v in drive_files.values())
                self._emit(7, "drive_archive", "running",
                           f"{total_files}ê°œ íŒŒì¼ Drive ì—…ë¡œë“œ ì¤‘...")

                # DriveArchiverë¡œ ì—…ë¡œë“œ
                archiver = DriveArchiver()
                if archiver.authenticate():
                    def _progress(cur, tot, fname):
                        self._emit(7, "drive_archive", "running",
                                   f"Drive ì—…ë¡œë“œ {cur}/{tot}: {fname}")

                    archive_result = archiver.archive_campaign(
                        campaign_obj, drive_files, progress_callback=_progress
                    )

                    if archive_result["ok"]:
                        folder_url = archive_result.get("folder_url", "")
                        uploaded = archive_result["files_uploaded"]
                        self._emit(7, "drive_archive", "complete",
                                   f"Drive ì•„ì¹´ì´ë¹™ ì™„ë£Œ: {uploaded}ê°œ íŒŒì¼ ì—…ë¡œë“œ")
                        results["drive_url"] = folder_url
                        results["drive_files_uploaded"] = uploaded
                    else:
                        errors = archive_result.get("errors", [])
                        self._emit(7, "drive_archive", "error",
                                   f"ì¼ë¶€ ì‹¤íŒ¨: {', '.join(errors[:3])}")
                else:
                    self._emit(7, "drive_archive", "error",
                               "Drive ì¸ì¦ ì‹¤íŒ¨ â€” OAuth í† í°ì„ í™•ì¸í•˜ì„¸ìš”")
            except Exception as e:
                self._emit(7, "drive_archive", "error", str(e))
        else:
            self._emit(7, "drive_archive", "skipped", "Drive ì•„ì¹´ì´ë¹™ ê±´ë„ˆëœ€")

        results["campaign_id"] = campaign_id
        return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API ì—”ë“œí¬ì¸íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€ ë©”ì¸ í˜ì´ì§€ â”€â”€
@app.route('/')
def index():
    return send_file(str(Path(__file__).parent / 'index.html'))


# â”€â”€ ê±´ê°• ì²´í¬ (AI 8ê°œ + ë¯¸ë””ì–´ + OpenClaw) â”€â”€
@app.route('/api/health')
def health():
    # AI í”„ë¡œë°”ì´ë” ìƒíƒœ
    providers = ai_service.list_providers()
    services = {}
    for p in providers:
        services[p["name"]] = p["available"]
    # ë¯¸ë””ì–´ API
    services["pexels"] = bool(PEXELS_API_KEY)
    services["pixabay"] = bool(PIXABAY_API_KEY)
    services["unsplash"] = bool(UNSPLASH_ACCESS_KEY)
    # OpenClaw ê²Œì´íŠ¸ì›¨ì´
    try:
        import requests as req
        oc = req.get("http://127.0.0.1:18792/__openclaw__/health", timeout=2)
        services["openclaw"] = oc.status_code == 200
    except Exception:
        services["openclaw"] = False

    return jsonify({
        "status": "online",
        "services": services,
        "active_jobs": sum(1 for j in jobs.values() if j["status"] == "running"),
        "ai_providers": providers,
        "timestamp": datetime.now().isoformat(),
    })


# â”€â”€ ë¸Œëœë“œ ëª©ë¡ â”€â”€
@app.route('/api/brands')
def get_brands():
    return jsonify(BRANDS)


# â”€â”€ ìº í˜ì¸ ì‹œì‘ â”€â”€
@app.route('/api/campaign/start', methods=['POST'])
def start_campaign():
    data = request.json or {}
    topic = data.get("topic", "").strip()
    if not topic:
        return jsonify({"error": "topic í•„ìˆ˜"}), 400

    brand = data.get("brand", "")
    platforms = data.get("platforms", ["youtube", "instagram", "naver_blog"])
    persona = data.get("persona", "")
    auto_upload = data.get("auto_upload", False)
    drive_archive = data.get("drive_archive", True)  # ê¸°ë³¸ ON

    job_id = uuid.uuid4().hex[:12]
    events_queue = Queue()

    jobs[job_id] = {
        "status": "pending",
        "step": 0,
        "topic": topic,
        "brand": brand,
        "platforms": platforms,
        "results": None,
        "error": None,
        "events": events_queue,
        "created_at": datetime.now().isoformat(),
    }

    # ìº í˜ì¸ íˆìŠ¤í† ë¦¬ ì €ì¥ (ì‹œì‘)
    _save_campaign(job_id, topic, brand, platforms, "running")

    def worker():
        job = jobs[job_id]
        job["status"] = "running"
        try:
            wp = WebPipeline(events_queue)
            results = wp.run(topic, platforms, brand, persona, auto_upload, drive_archive)
            job["results"] = results
            job["status"] = "complete"
            events_queue.put({"type": "complete", "results": results})
            # ìº í˜ì¸ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (ì™„ë£Œ)
            _save_campaign(job_id, topic, brand, platforms, "complete",
                           results=_safe_serialize(results))
        except Exception as e:
            job["error"] = str(e)
            job["status"] = "error"
            events_queue.put({"type": "error", "error": str(e)})
            _save_campaign(job_id, topic, brand, platforms, "error")

    thread = threading.Thread(target=worker, daemon=True)
    thread.start()

    return jsonify({"job_id": job_id, "status": "started"})


# â”€â”€ SSE ì§„í–‰ìƒí™© ìŠ¤íŠ¸ë¦¬ë° â”€â”€
@app.route('/api/campaign/stream/<job_id>')
def stream_campaign(job_id):
    def generate():
        job = jobs.get(job_id)
        if not job:
            yield f"data: {json.dumps({'type': 'error', 'error': 'Job not found'})}\n\n"
            return

        q = job["events"]
        while job["status"] in ("pending", "running"):
            while not q.empty():
                event = q.get_nowait()
                # ê²°ê³¼ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë³€í™˜
                if event.get("type") == "complete" and event.get("results"):
                    event["results"] = _safe_serialize(event["results"])
                yield f"data: {json.dumps(event, ensure_ascii=False, default=str)}\n\n"
            time.sleep(0.3)

        # ì”ì—¬ ì´ë²¤íŠ¸ flush
        while not q.empty():
            event = q.get_nowait()
            if event.get("type") == "complete" and event.get("results"):
                event["results"] = _safe_serialize(event["results"])
            yield f"data: {json.dumps(event, ensure_ascii=False, default=str)}\n\n"

        # ìµœì¢… ìƒíƒœ
        if job["status"] == "complete" and job["results"]:
            yield f"data: {json.dumps({'type': 'done', 'results': _safe_serialize(job['results'])}, ensure_ascii=False, default=str)}\n\n"
        elif job["status"] == "error":
            yield f"data: {json.dumps({'type': 'error', 'error': job['error']})}\n\n"

    return Response(generate(), mimetype='text/event-stream',
                    headers={'Cache-Control': 'no-cache', 'X-Accel-Buffering': 'no'})


def _safe_serialize(obj):
    """ê²°ê³¼ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë³€í™˜."""
    if isinstance(obj, dict):
        return {k: _safe_serialize(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [_safe_serialize(v) for v in obj]
    if isinstance(obj, Path):
        return str(obj)
    if hasattr(obj, '__dict__') and not isinstance(obj, type):
        return str(obj)
    return obj


# â”€â”€ AI ì½˜í…ì¸ ë§Œ ìƒì„± (ì˜ìƒ ì—†ì´) â”€â”€
@app.route('/api/content/generate', methods=['POST'])
def generate_content():
    data = request.json or {}
    topic = data.get("topic", "").strip()
    if not topic:
        return jsonify({"error": "topic í•„ìˆ˜"}), 400

    brand = data.get("brand", "")
    persona = data.get("persona", "")
    platforms = data.get("platforms", ["youtube", "instagram", "naver_blog"])

    try:
        from affiliate_system.pipeline import ContentPipeline
        pipeline = ContentPipeline()
        product = pipeline._prepare_product(topic)

        platform_enums = [PLATFORM_MAP[p] for p in platforms if p in PLATFORM_MAP]
        contents = pipeline._generate_contents(product, platform_enums, persona, brand)

        return jsonify({
            "product": {"title": product.title, "description": product.description},
            "contents": contents,
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â”€â”€ ë¬´ë£Œ ë¯¸ë””ì–´ ê²€ìƒ‰ â”€â”€
@app.route('/api/media/search', methods=['POST'])
def search_media():
    data = request.json or {}
    query = data.get("query", "").strip()
    media_type = data.get("type", "image")  # image or video

    if not query:
        return jsonify({"error": "query í•„ìˆ˜"}), 400

    try:
        from affiliate_system.media_collector import MediaCollector
        mc = MediaCollector()

        if media_type == "video":
            results = mc.search_videos(query, count=6)
        else:
            results = mc.search_images(query, count=12)

        return jsonify({"results": results, "query": query, "type": media_type})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â”€â”€ ì†Œì…œ ë¯¸ë””ì–´ ë‹¤ìš´ë¡œë“œ (TikTok, YouTube ë“±) â”€â”€
@app.route('/api/media/social', methods=['POST'])
def download_social():
    data = request.json or {}
    url = data.get("url", "").strip()

    if not url:
        return jsonify({"error": "url í•„ìˆ˜"}), 400

    try:
        from affiliate_system.media_collector import MediaCollector
        mc = MediaCollector()
        result = mc.download_from_social(url)
        return jsonify({"result": result})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â”€â”€ AI ì´ë¯¸ì§€ ìƒì„± (Gemini) â”€â”€
@app.route('/api/media/ai-generate', methods=['POST'])
def ai_generate():
    data = request.json or {}
    prompt = data.get("prompt", "").strip()
    media_type = data.get("type", "image")

    if not prompt:
        return jsonify({"error": "prompt í•„ìˆ˜"}), 400

    try:
        import google.generativeai as genai
        genai.configure(api_key=GEMINI_API_KEY)

        if media_type == "image":
            # Gemini ì´ë¯¸ì§€ ìƒì„±
            model = genai.GenerativeModel('gemini-2.0-flash-exp')
            response = model.generate_content(prompt)
            # í…ìŠ¤íŠ¸ ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
            return jsonify({
                "type": "image",
                "prompt_used": prompt,
                "response": response.text if response.text else "ìƒì„± ì™„ë£Œ",
            })
        else:
            return jsonify({"error": "video AI ìƒì„±ì€ ì¤€ë¹„ ì¤‘"}), 501
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â”€â”€ ë¹„ìš© í˜„í™© (ì»¤ë§¨ë“œì„¼í„° ì—°ë™) â”€â”€
@app.route('/api/cost')
def get_cost():
    try:
        from api_cost_tracker import CostTracker
        tracker = CostTracker()
        summary = tracker.get_summary()
    except Exception:
        summary = {"total_usd": 0}

    # AI í”„ë¡œë°”ì´ë”ë³„ ë¹„ìš© ì •ë³´
    summary["providers"] = {}
    for name, info in AI_PROVIDERS.items():
        summary["providers"][name] = {
            "model": info["model"],
            "cost_tier": info["cost"],
        }
    return jsonify(summary)


# â”€â”€ AI í”„ë¡œë°”ì´ë” ëª©ë¡ â”€â”€
@app.route('/api/ai/providers')
def ai_providers():
    return jsonify(ai_service.list_providers())


# â”€â”€ AI ì§ì ‘ í˜¸ì¶œ (í…ŒìŠ¤íŠ¸/ë‹¨ë… ì‚¬ìš©) â”€â”€
@app.route('/api/ai/ask', methods=['POST'])
def ai_ask():
    data = request.json or {}
    prompt = data.get("prompt", "").strip()
    provider = data.get("provider")  # Noneì´ë©´ ìë™ í´ë°±
    if not prompt:
        return jsonify({"error": "prompt í•„ìˆ˜"}), 400

    try:
        resp = ai_service.ask(prompt, provider=provider)
        return jsonify({
            "text": resp.text,
            "provider": resp.provider,
            "model": resp.model,
            "tokens": {"input": resp.input_tokens, "output": resp.output_tokens},
            "cost_usd": resp.cost_usd,
            "elapsed_ms": resp.elapsed_ms,
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â”€â”€ ìº í˜ì¸ íˆìŠ¤í† ë¦¬ â”€â”€
@app.route('/api/campaigns')
def list_campaigns():
    """ìµœê·¼ ìº í˜ì¸ ì´ë ¥ ì¡°íšŒ"""
    limit = request.args.get("limit", 20, type=int)
    conn = sqlite3.connect(CAMPAIGN_DB)
    conn.row_factory = sqlite3.Row
    rows = conn.execute(
        "SELECT * FROM campaigns ORDER BY created_at DESC LIMIT ?", (limit,)
    ).fetchall()
    conn.close()
    return jsonify([dict(r) for r in rows])


@app.route('/api/campaigns/<campaign_id>')
def get_campaign(campaign_id):
    """íŠ¹ì • ìº í˜ì¸ ìƒì„¸ ì¡°íšŒ"""
    conn = sqlite3.connect(CAMPAIGN_DB)
    conn.row_factory = sqlite3.Row
    row = conn.execute("SELECT * FROM campaigns WHERE id = ?", (campaign_id,)).fetchone()
    conn.close()
    if not row:
        return jsonify({"error": "ìº í˜ì¸ ì—†ìŒ"}), 404
    result = dict(row)
    # ê²°ê³¼ JSON íŒŒì‹±
    if result.get("results"):
        try:
            result["results"] = json.loads(result["results"])
        except Exception:
            pass
    return jsonify(result)


def _save_campaign(campaign_id, topic, brand, platforms, status, results=None, cost=0.0):
    """ìº í˜ì¸ ì´ë ¥ DB ì €ì¥"""
    conn = sqlite3.connect(CAMPAIGN_DB)
    conn.execute("""INSERT OR REPLACE INTO campaigns
        (id, topic, brand, platforms, status, results, cost_usd, created_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)""",
        (campaign_id, topic, brand, json.dumps(platforms),
         status, json.dumps(results) if results else None,
         cost, datetime.now().isoformat())
    )
    conn.commit()
    conn.close()


# â”€â”€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ/ë¯¸ë¦¬ë³´ê¸° (ë Œë”ë§ëœ ì˜ìƒ/ì´ë¯¸ì§€) â”€â”€
@app.route('/api/file/<path:filepath>')
def serve_file(filepath):
    full_path = PROJECT_DIR / filepath
    if full_path.exists() and full_path.is_file():
        # MIME íƒ€ì… ìë™ ê°ì§€ + ë¹„ë””ì˜¤/ì´ë¯¸ì§€ëŠ” inline í‘œì‹œ
        suffix = full_path.suffix.lower()
        mime_map = {
            '.mp4': 'video/mp4', '.webm': 'video/webm', '.avi': 'video/x-msvideo',
            '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png',
            '.gif': 'image/gif', '.webp': 'image/webp',
        }
        mimetype = mime_map.get(suffix)
        return send_file(str(full_path), mimetype=mimetype)
    return jsonify({"error": "íŒŒì¼ ì—†ìŒ"}), 404


# â”€â”€ ë Œë”ë§ ì¶œë ¥ í´ë” ì§ì ‘ ëª©ë¡ (ë””ë²„ê¹…ìš©) â”€â”€
@app.route('/api/renders')
def list_renders():
    renders_dir = PROJECT_DIR / "affiliate_system" / "renders"
    if not renders_dir.exists():
        return jsonify({"files": []})
    files = []
    for f in sorted(renders_dir.iterdir(), key=lambda x: x.stat().st_mtime, reverse=True):
        if f.is_file():
            files.append({
                "name": f.name,
                "size_mb": round(f.stat().st_size / (1024*1024), 2),
                "url": f"/api/file/affiliate_system/renders/{f.name}",
                "modified": datetime.fromtimestamp(f.stat().st_mtime).isoformat(),
            })
    return jsonify({"files": files[:50]})


# â”€â”€ Google Drive ìƒíƒœ â”€â”€
@app.route('/api/drive/status')
def drive_status():
    """Google Drive ì¸ì¦ ìƒíƒœ ë° ì €ì¥ìš©ëŸ‰ í™•ì¸"""
    try:
        from affiliate_system.drive_manager import DriveArchiver
        archiver = DriveArchiver()
        token_path = archiver.TOKEN_PATH
        token_exists = token_path.exists()

        if token_exists and archiver.authenticate():
            usage = archiver.get_storage_usage()
            return jsonify({
                "authenticated": True,
                "token_path": str(token_path),
                "storage": usage,
            })
        else:
            return jsonify({
                "authenticated": False,
                "token_path": str(token_path),
                "token_exists": token_exists,
                "error": "ì¸ì¦ í•„ìš”" if not token_exists else "í† í° ë§Œë£Œ",
            })
    except Exception as e:
        return jsonify({"authenticated": False, "error": str(e)})


@app.route('/api/drive/campaigns')
def drive_campaigns():
    """Google Driveì— ì•„ì¹´ì´ë¹™ëœ ìº í˜ì¸ ëª©ë¡"""
    try:
        from affiliate_system.drive_manager import DriveArchiver
        archiver = DriveArchiver()
        if archiver.authenticate():
            campaigns = archiver.list_campaigns()
            return jsonify({"campaigns": campaigns})
        return jsonify({"error": "Drive ì¸ì¦ ì‹¤íŒ¨"}), 401
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# â”€â”€ ìº í˜ì¸ ìƒíƒœ ì¡°íšŒ â”€â”€
@app.route('/api/campaign/status/<job_id>')
def campaign_status(job_id):
    job = jobs.get(job_id)
    if not job:
        return jsonify({"error": "Job not found"}), 404

    resp = {
        "job_id": job_id,
        "status": job["status"],
        "topic": job["topic"],
        "brand": job["brand"],
        "platforms": job["platforms"],
        "created_at": job["created_at"],
        "error": job.get("error"),
    }
    if job["status"] == "complete" and job["results"]:
        resp["results"] = _safe_serialize(job["results"])
    return jsonify(resp)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# V2 â€” ëŒ€í™”í˜• ì¿ íŒ¡ ìˆ˜ìµ ê·¹ëŒ€í™” íŒŒì´í”„ë¼ì¸ API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# V2 Job ì €ì¥ì†Œ (interactive ìƒíƒœë¨¸ì‹ )
v2_jobs = {}  # job_id -> {state, coupang_link, product, draft, events, ...}


class V2PipelineState:
    """V2 ëŒ€í™”í˜• íŒŒì´í”„ë¼ì¸ ìƒíƒœ enum."""
    IDLE = "idle"
    AWAITING_LINK = "awaiting_link"
    ANALYZING = "analyzing"
    AWAITING_CONFIRM = "awaiting_confirm"
    EXECUTING = "executing"
    COMPLETE = "complete"
    ERROR = "error"


# V2 10ë‹¨ê³„ ì •ì˜
V2_STEPS = [
    {"step": 1,  "name": "prep_report",    "label": "ì¤€ë¹„ ë¦¬í¬íŠ¸",           "module": "pipeline"},
    {"step": 2,  "name": "link_analysis",   "label": "ì¿ íŒ¡ ë§í¬ ë¶„ì„",       "module": "coupang_scraper"},
    {"step": 3,  "name": "ai_content",      "label": "AI ì½˜í…ì¸  ìƒì„±",       "module": "ai_generator V2"},
    {"step": 4,  "name": "media_crawl",     "label": "ë¯¸ë””ì–´ í¬ë¡¤ë§",         "module": "OmniMediaCollector"},
    {"step": 5,  "name": "blog_compose",    "label": "ë¸”ë¡œê·¸ HTML ì¡°ë¦½",      "module": "blog_html_generator"},
    {"step": 6,  "name": "video_launder",   "label": "4ë‹¨ê³„ ì˜ìƒ ì„¸íƒ",       "module": "video_launderer (FFmpeg GPU)"},
    {"step": 7,  "name": "shorts_render",   "label": "ìˆí¼ ë Œë”ë§",          "module": "ShortsRenderer + TTS + Whisper"},
    {"step": 8,  "name": "thumbnail",       "label": "ì¸ë„¤ì¼ ìƒì„±",          "module": "thumbnail_generator"},
    {"step": 9,  "name": "upload_ready",    "label": "ì—…ë¡œë“œ ì¤€ë¹„",          "module": "auto_uploader V2"},
    {"step": 10, "name": "drive_archive",   "label": "Drive ì•„ì¹´ì´ë¹™",       "module": "drive_manager"},
]


@app.route('/api/v2/steps')
def v2_steps():
    """V2 10ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì •ì˜ ë°˜í™˜."""
    return jsonify(V2_STEPS)


@app.route('/api/v2/campaign/start', methods=['POST'])
def v2_start_campaign():
    """V2 ëŒ€í™”í˜• ìº í˜ì¸ ì‹œì‘ â€” "ì¿ íŒ¡ ë§í¬ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”" ìƒíƒœë¡œ ì§„ì…."""
    job_id = uuid.uuid4().hex[:12]
    events_queue = Queue()

    v2_jobs[job_id] = {
        "state": V2PipelineState.AWAITING_LINK,
        "coupang_link": None,
        "product_info": None,
        "draft": None,
        "blog_html": None,
        "shorts_script": None,
        "results": {},
        "error": None,
        "events": events_queue,
        "created_at": datetime.now().isoformat(),
        "platforms": ["naver_blog", "youtube", "instagram"],
    }

    events_queue.put({
        "type": "state_change",
        "state": V2PipelineState.AWAITING_LINK,
        "message": "ğŸ”— ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ ë§í¬ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”!",
        "timestamp": datetime.now().isoformat(),
    })

    return jsonify({
        "job_id": job_id,
        "state": V2PipelineState.AWAITING_LINK,
        "message": "ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ ë§í¬ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”",
    })


@app.route('/api/v2/campaign/<job_id>/link', methods=['POST'])
def v2_submit_link(job_id):
    """V2 ì¿ íŒ¡ ë§í¬ ì œì¶œ â†’ ìƒí’ˆ ë¶„ì„ ì‹œì‘."""
    job = v2_jobs.get(job_id)
    if not job:
        return jsonify({"error": "Job not found"}), 404
    if job["state"] != V2PipelineState.AWAITING_LINK:
        return jsonify({"error": f"í˜„ì¬ ìƒíƒœ: {job['state']}, ë§í¬ ì…ë ¥ ë¶ˆê°€"}), 400

    data = request.json or {}
    coupang_link = data.get("coupang_link", "").strip()       # ìƒí’ˆì •ë³´ URL (ìŠ¤í¬ë˜í•‘ìš©)
    affiliate_link = data.get("affiliate_link", "").strip()   # ë‹¨ì¶• URL (ìˆ˜ìµ ë§í¬)
    iframe_tag = data.get("iframe_tag", "").strip()           # iframe íƒœê·¸ (ë¸”ë¡œê·¸ ìœ„ì ¯)
    product_name = data.get("product_name", "").strip()
    if not coupang_link:
        return jsonify({"error": "ìƒí’ˆì •ë³´ ë§í¬ í•„ìˆ˜"}), 400
    if not affiliate_link:
        return jsonify({"error": "ë‹¨ì¶• URL í•„ìˆ˜"}), 400

    job["coupang_link"] = coupang_link
    job["affiliate_link"] = affiliate_link
    job["iframe_tag"] = iframe_tag
    job["product_name"] = product_name
    job["state"] = V2PipelineState.ANALYZING
    job["events"].put({
        "type": "state_change",
        "state": V2PipelineState.ANALYZING,
        "message": "ğŸ” ìƒí’ˆ ë¶„ì„ ì¤‘...",
        "timestamp": datetime.now().isoformat(),
    })

    # ë¹„ë™ê¸° ë¶„ì„
    def analyze():
        try:
            # Step 1: ì¤€ë¹„
            job["events"].put({
                "type": "v2_step", "step": 1, "name": "prep_report",
                "status": "complete", "detail": "V2 íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ",
                "timestamp": datetime.now().isoformat(),
            })

            # Step 2: ë§í¬ ë¶„ì„
            job["events"].put({
                "type": "v2_step", "step": 2, "name": "link_analysis",
                "status": "running", "detail": "ì¿ íŒ¡ ë§í¬ ìŠ¤í¬ë˜í•‘ ì¤‘...",
                "timestamp": datetime.now().isoformat(),
            })

            from affiliate_system.pipeline import ContentPipeline
            from affiliate_system.models import Product
            pipeline = ContentPipeline()
            product = pipeline._prepare_product(coupang_link)

            # ì¿ íŒ¡ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ì ì…ë ¥ ìƒí’ˆëª… ì‚¬ìš©
            if product_name and (not product.title or product.title in ("ì¿ íŒ¡ ìƒí’ˆ", "ì¸ê¸°ìƒí’ˆ")):
                print(f"[V2] ìŠ¤í¬ë˜í•‘ í´ë°± â†’ ì‚¬ìš©ì ìƒí’ˆëª… ì‚¬ìš©: {product_name}")
                product = Product(
                    title=product_name,
                    description=f"{product_name} - ì¿ íŒ¡ ìµœì €ê°€ ìƒí’ˆ",
                    url=coupang_link,
                    affiliate_link=affiliate_link,  # ìˆ˜ìµ ë§í¬
                    scraped_at=product.scraped_at,
                )

            # í•­ìƒ ìˆ˜ìµ ë§í¬ë¥¼ íŒŒíŠ¸ë„ˆìŠ¤ ë§í¬ë¡œ ì„¤ì •
            product.affiliate_link = affiliate_link

            product_info = {
                "title": product.title,
                "description": product.description or "",
                "price": product.price or "",
                "image_urls": product.image_urls[:3] if product.image_urls else [],
                "affiliate_link": affiliate_link,  # ìˆ˜ìµ ë§í¬ (link.coupang.com/a/...)
                "product_url": coupang_link,        # ìƒí’ˆì •ë³´ ë§í¬ (coupang.com/vp/products/...)
            }
            job["product_info"] = product_info

            job["events"].put({
                "type": "v2_step", "step": 2, "name": "link_analysis",
                "status": "complete",
                "detail": f"ìƒí’ˆ: {product.title}",
                "timestamp": datetime.now().isoformat(),
            })

            # Step 3: AI ì½˜í…ì¸  ì´ˆì•ˆ ìƒì„±
            job["events"].put({
                "type": "v2_step", "step": 3, "name": "ai_content",
                "status": "running", "detail": "ë¸”ë¡œê·¸ + ìˆí¼ ëŒ€ë³¸ AI ìƒì„± ì¤‘ (Gemini ë¬´ë£Œ)...",
                "timestamp": datetime.now().isoformat(),
            })

            try:
                from affiliate_system.ai_generator import AIGenerator
                generator = AIGenerator()

                # V2 ë¸”ë¡œê·¸ ì½˜í…ì¸  â€” ìˆ˜ìµ ë§í¬ë¡œ ìƒì„±
                blog_content = generator.generate_blog_content_v2(product, affiliate_link)
                job["draft"] = {
                    "blog": blog_content,
                    "product": product_info,
                }

                # V2 ìˆí¼ í›„í‚¹ ëŒ€ë³¸
                try:
                    shorts_script = generator.generate_shorts_hooking_script(
                        product, persona="", coupang_link=affiliate_link, dm_keyword="ë§í¬"
                    )
                    job["shorts_script"] = shorts_script
                    job["draft"]["shorts"] = shorts_script
                except Exception as se:
                    job["draft"]["shorts"] = {"error": str(se)}

                job["events"].put({
                    "type": "v2_step", "step": 3, "name": "ai_content",
                    "status": "complete",
                    "detail": f"ë¸”ë¡œê·¸ {len(blog_content.get('body_sections', []))}ì„¹ì…˜ + ìˆí¼ ëŒ€ë³¸ ìƒì„± ì™„ë£Œ",
                    "timestamp": datetime.now().isoformat(),
                })

            except Exception as ai_err:
                job["events"].put({
                    "type": "v2_step", "step": 3, "name": "ai_content",
                    "status": "error", "detail": str(ai_err),
                    "timestamp": datetime.now().isoformat(),
                })

            # í™•ì¸ ëŒ€ê¸° ìƒíƒœë¡œ ì „í™˜
            job["state"] = V2PipelineState.AWAITING_CONFIRM
            job["events"].put({
                "type": "state_change",
                "state": V2PipelineState.AWAITING_CONFIRM,
                "message": "âœ… ë¶„ì„ ì™„ë£Œ! ì´ˆì•ˆì„ í™•ì¸í•˜ê³  ì‹¤í–‰ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.",
                "draft": job["draft"],
                "timestamp": datetime.now().isoformat(),
            })

        except Exception as e:
            job["state"] = V2PipelineState.ERROR
            job["error"] = str(e)
            job["events"].put({
                "type": "error", "error": str(e),
                "timestamp": datetime.now().isoformat(),
            })

    thread = threading.Thread(target=analyze, daemon=True)
    thread.start()

    return jsonify({"job_id": job_id, "state": V2PipelineState.ANALYZING})


@app.route('/api/v2/campaign/<job_id>/confirm', methods=['POST'])
def v2_confirm_execute(job_id):
    """V2 ì‹¤í–‰ í™•ì¸ â†’ ë‚˜ë¨¸ì§€ 7ë‹¨ê³„ (ë¯¸ë””ì–´ í¬ë¡¤ë§ ~ Drive ì•„ì¹´ì´ë¹™) ì‹¤í–‰."""
    job = v2_jobs.get(job_id)
    if not job:
        return jsonify({"error": "Job not found"}), 404
    if job["state"] != V2PipelineState.AWAITING_CONFIRM:
        return jsonify({"error": f"í˜„ì¬ ìƒíƒœ: {job['state']}, ì‹¤í–‰ í™•ì¸ ë¶ˆê°€"}), 400

    job["state"] = V2PipelineState.EXECUTING
    job["events"].put({
        "type": "state_change",
        "state": V2PipelineState.EXECUTING,
        "message": "ğŸš€ ì‹¤í–‰ ì‹œì‘! 10ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì§„í–‰ ì¤‘...",
        "timestamp": datetime.now().isoformat(),
    })

    def execute():
        try:
            coupang_link = job["coupang_link"]
            draft = job.get("draft", {})
            blog_content = draft.get("blog", {})
            product_info = job.get("product_info", {})

            # Step 4: ë¯¸ë””ì–´ í¬ë¡¤ë§
            job["events"].put({
                "type": "v2_step", "step": 4, "name": "media_crawl",
                "status": "running", "detail": "ë¸”ë¡œê·¸ ì´ë¯¸ì§€ + ìˆí¼ ì˜ìƒ ìˆ˜ì§‘ ì¤‘...",
                "timestamp": datetime.now().isoformat(),
            })
            blog_images = []
            video_sources = []
            try:
                from affiliate_system.media_collector import OmniMediaCollector, MediaCollector
                omni = OmniMediaCollector()

                # ë¸”ë¡œê·¸ ì´ë¯¸ì§€ ìˆ˜ì§‘
                image_keywords = blog_content.get("image_keywords", [product_info.get("title", "ìƒí’ˆ")])
                from affiliate_system.pipeline import ContentPipeline
                pipeline = ContentPipeline()
                product = pipeline._prepare_product(coupang_link)
                blog_images = omni.collect_blog_images(product, image_keywords)

                # ìˆí¼ ì˜ìƒ ìˆ˜ì§‘
                try:
                    video_sources = omni.collect_video_sources(product, count=5)
                except Exception:
                    video_sources = []

                job["events"].put({
                    "type": "v2_step", "step": 4, "name": "media_crawl",
                    "status": "complete",
                    "detail": f"ì´ë¯¸ì§€ {len(blog_images)}ì¥ + ì˜ìƒ {len(video_sources)}ê°œ ìˆ˜ì§‘",
                    "timestamp": datetime.now().isoformat(),
                })
            except Exception as me:
                job["events"].put({
                    "type": "v2_step", "step": 4, "name": "media_crawl",
                    "status": "error", "detail": str(me),
                    "timestamp": datetime.now().isoformat(),
                })

            # Step 5: ë¸”ë¡œê·¸ HTML ì¡°ë¦½
            job["events"].put({
                "type": "v2_step", "step": 5, "name": "blog_compose",
                "status": "running", "detail": "ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ êµì°¨ ë°°ì¹˜ HTML ìƒì„± ì¤‘...",
                "timestamp": datetime.now().isoformat(),
            })
            blog_html = ""
            try:
                from affiliate_system.blog_html_generator import NaverBlogHTMLGenerator
                html_gen = NaverBlogHTMLGenerator()
                blog_html = html_gen.generate_blog_html(
                    title=blog_content.get("title", product_info.get("title", "")),
                    intro=blog_content.get("intro", ""),
                    body_sections=blog_content.get("body_sections", []),
                    image_paths=blog_images,
                    coupang_link=coupang_link,
                    hashtags=blog_content.get("hashtags", []),
                )
                job["blog_html"] = blog_html
                job["events"].put({
                    "type": "v2_step", "step": 5, "name": "blog_compose",
                    "status": "complete",
                    "detail": f"HTML {len(blog_html)}ì ìƒì„± (ì´ë¯¸ì§€ {len(blog_images)}ì¥ êµì°¨ ë°°ì¹˜)",
                    "timestamp": datetime.now().isoformat(),
                })
            except Exception as he:
                job["events"].put({
                    "type": "v2_step", "step": 5, "name": "blog_compose",
                    "status": "error", "detail": str(he),
                    "timestamp": datetime.now().isoformat(),
                })

            # Step 6: ì˜ìƒ ì„¸íƒ
            job["events"].put({
                "type": "v2_step", "step": 6, "name": "video_launder",
                "status": "running", "detail": "4ë‹¨ê³„ FFmpeg GPU ì„¸íƒ ì¤‘...",
                "timestamp": datetime.now().isoformat(),
            })
            laundered_videos = []
            try:
                if video_sources:
                    from affiliate_system.video_launderer import VideoLaunderer
                    launderer = VideoLaunderer()
                    video_paths = [v["path"] for v in video_sources if v.get("path")]
                    laundered_videos = launderer.batch_launder(video_paths)
                    job["events"].put({
                        "type": "v2_step", "step": 6, "name": "video_launder",
                        "status": "complete",
                        "detail": f"{len(laundered_videos)}ê°œ ì˜ìƒ ì„¸íƒ ì™„ë£Œ",
                        "timestamp": datetime.now().isoformat(),
                    })
                else:
                    job["events"].put({
                        "type": "v2_step", "step": 6, "name": "video_launder",
                        "status": "complete", "detail": "ì˜ìƒ ì—†ìŒ (í”Œë ˆì´ìŠ¤í™€ë”)",
                        "timestamp": datetime.now().isoformat(),
                    })
            except Exception as le:
                job["events"].put({
                    "type": "v2_step", "step": 6, "name": "video_launder",
                    "status": "error", "detail": str(le),
                    "timestamp": datetime.now().isoformat(),
                })

            # Step 7: ìˆí¼ ë Œë”ë§
            job["events"].put({
                "type": "v2_step", "step": 7, "name": "shorts_render",
                "status": "running", "detail": "TTS + ìë§‰ ì‹±í¬ + ìˆí¼ ì¡°ë¦½ ì¤‘...",
                "timestamp": datetime.now().isoformat(),
            })
            shorts_path = None
            try:
                if laundered_videos and job.get("shorts_script"):
                    from affiliate_system.video_launderer import (
                        EmotionTTSEngine, SubtitleGenerator, ShortsRenderer
                    )
                    from affiliate_system.config import V2_TTS_DIR, V2_SUBTITLE_DIR, V2_SHORTS_DIR
                    from affiliate_system.models import ShortsScene, EmotionTag

                    script = job["shorts_script"]
                    scenes_data = script.get("scenes", [])

                    # ShortsScene ê°ì²´ ìƒì„±
                    scenes = []
                    for sd in scenes_data:
                        emotion_str = sd.get("emotion", "friendly")
                        try:
                            emotion = EmotionTag(emotion_str)
                        except ValueError:
                            emotion = EmotionTag.FRIENDLY
                        scenes.append(ShortsScene(
                            scene_num=sd.get("scene_num", len(scenes) + 1),
                            text=sd.get("text", ""),
                            duration=sd.get("duration", 5.0),
                            emotion=emotion,
                        ))

                    # TTS ìƒì„±
                    tts_engine = EmotionTTSEngine()
                    scenes = tts_engine.generate_scenes_tts(scenes, str(V2_TTS_DIR))

                    # ìë§‰ ìƒì„±
                    sub_gen = SubtitleGenerator()
                    subtitle_path = str(V2_SUBTITLE_DIR / "shorts_subtitle.ass")
                    sub_gen.generate_ass_from_scenes(scenes, subtitle_path)

                    # ìµœì¢… ë Œë”ë§
                    renderer = ShortsRenderer()
                    shorts_path = str(V2_SHORTS_DIR / "final_shorts.mp4")
                    renderer.render_final_shorts(
                        scenes=scenes,
                        laundered_videos=laundered_videos,
                        subtitle_path=subtitle_path,
                        output_path=shorts_path,
                    )

                    job["events"].put({
                        "type": "v2_step", "step": 7, "name": "shorts_render",
                        "status": "complete",
                        "detail": f"ìˆí¼ ë Œë”ë§ ì™„ë£Œ: {Path(shorts_path).name}",
                        "timestamp": datetime.now().isoformat(),
                    })
                else:
                    job["events"].put({
                        "type": "v2_step", "step": 7, "name": "shorts_render",
                        "status": "complete", "detail": "ì˜ìƒ ì†ŒìŠ¤ ë¶€ì¡± (í”Œë ˆì´ìŠ¤í™€ë”)",
                        "timestamp": datetime.now().isoformat(),
                    })
            except Exception as re:
                job["events"].put({
                    "type": "v2_step", "step": 7, "name": "shorts_render",
                    "status": "error", "detail": str(re),
                    "timestamp": datetime.now().isoformat(),
                })

            # Step 8: ì¸ë„¤ì¼
            job["events"].put({
                "type": "v2_step", "step": 8, "name": "thumbnail",
                "status": "running", "detail": "í”Œë«í¼ë³„ ì¸ë„¤ì¼ ìƒì„± ì¤‘...",
                "timestamp": datetime.now().isoformat(),
            })
            try:
                # ì¸ë„¤ì¼ì€ V1 íŒŒì´í”„ë¼ì¸ ì¬ì‚¬ìš©
                job["events"].put({
                    "type": "v2_step", "step": 8, "name": "thumbnail",
                    "status": "complete", "detail": "ì¸ë„¤ì¼ ìƒì„± ì™„ë£Œ (ë˜ëŠ” ìƒëµ)",
                    "timestamp": datetime.now().isoformat(),
                })
            except Exception as te:
                job["events"].put({
                    "type": "v2_step", "step": 8, "name": "thumbnail",
                    "status": "error", "detail": str(te),
                    "timestamp": datetime.now().isoformat(),
                })

            # Step 9: ì—…ë¡œë“œ ì¤€ë¹„
            job["events"].put({
                "type": "v2_step", "step": 9, "name": "upload_ready",
                "status": "running", "detail": "ì—…ë¡œë“œ íŒŒì¼ ì¤€ë¹„ ì¤‘...",
                "timestamp": datetime.now().isoformat(),
            })
            upload_results = {}
            try:
                job["results"]["blog_html"] = blog_html[:500] + "..." if len(blog_html) > 500 else blog_html
                job["results"]["blog_images"] = blog_images
                job["results"]["shorts_path"] = shorts_path
                job["results"]["laundered_videos"] = laundered_videos

                job["events"].put({
                    "type": "v2_step", "step": 9, "name": "upload_ready",
                    "status": "complete",
                    "detail": "ì—…ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ (ìˆ˜ë™ ëª¨ë“œ â€” ê²°ê³¼ë¬¼ í™•ì¸ í›„ ì—…ë¡œë“œ)",
                    "timestamp": datetime.now().isoformat(),
                })
            except Exception as ue:
                job["events"].put({
                    "type": "v2_step", "step": 9, "name": "upload_ready",
                    "status": "error", "detail": str(ue),
                    "timestamp": datetime.now().isoformat(),
                })

            # Step 10: Drive ì•„ì¹´ì´ë¹™
            job["events"].put({
                "type": "v2_step", "step": 10, "name": "drive_archive",
                "status": "running", "detail": "Google Drive ì•„ì¹´ì´ë¹™ ì¤‘...",
                "timestamp": datetime.now().isoformat(),
            })
            try:
                from affiliate_system.drive_manager import DriveArchiver
                archiver = DriveArchiver()
                if archiver.authenticate():
                    # V2 íŒŒì¼ ìˆ˜ì§‘
                    drive_files = {"images": blog_images, "renders": [], "audio": [], "logs": []}
                    if shorts_path and Path(shorts_path).exists():
                        drive_files["renders"].append(shorts_path)
                    for lv in laundered_videos:
                        if Path(lv).exists():
                            drive_files["renders"].append(lv)

                    # ì„ì‹œ Campaign ê°ì²´ ìƒì„±
                    from affiliate_system.models import Campaign, AIContent, CampaignStatus
                    from affiliate_system.pipeline import ContentPipeline
                    temp_pipeline = ContentPipeline()
                    temp_product = temp_pipeline._prepare_product(coupang_link)
                    temp_campaign = Campaign(
                        id=job_id, product=temp_product,
                        ai_content=AIContent(platform_contents={}),
                        status=CampaignStatus.COMPLETE,
                        target_platforms=[],
                        platform_videos={}, platform_thumbnails={},
                        created_at=datetime.now(),
                    )
                    archive_result = archiver.archive_campaign(temp_campaign, drive_files)
                    if archive_result["ok"]:
                        job["results"]["drive_url"] = archive_result.get("folder_url", "")
                        job["events"].put({
                            "type": "v2_step", "step": 10, "name": "drive_archive",
                            "status": "complete",
                            "detail": f"Drive ì•„ì¹´ì´ë¹™ ì™„ë£Œ: {archive_result['files_uploaded']}ê°œ íŒŒì¼",
                            "timestamp": datetime.now().isoformat(),
                        })
                    else:
                        job["events"].put({
                            "type": "v2_step", "step": 10, "name": "drive_archive",
                            "status": "error", "detail": "Drive ì—…ë¡œë“œ ì¼ë¶€ ì‹¤íŒ¨",
                            "timestamp": datetime.now().isoformat(),
                        })
                else:
                    job["events"].put({
                        "type": "v2_step", "step": 10, "name": "drive_archive",
                        "status": "error", "detail": "Drive ì¸ì¦ ì‹¤íŒ¨",
                        "timestamp": datetime.now().isoformat(),
                    })
            except Exception as de:
                job["events"].put({
                    "type": "v2_step", "step": 10, "name": "drive_archive",
                    "status": "error", "detail": str(de),
                    "timestamp": datetime.now().isoformat(),
                })

            # ì™„ë£Œ
            job["state"] = V2PipelineState.COMPLETE
            job["events"].put({
                "type": "v2_complete",
                "message": "ğŸ‰ V2 íŒŒì´í”„ë¼ì¸ 10ë‹¨ê³„ ì™„ë£Œ!",
                "results": _safe_serialize(job["results"]),
                "timestamp": datetime.now().isoformat(),
            })

            # ìº í˜ì¸ DB ì €ì¥
            _save_campaign(
                job_id, product_info.get("title", "V2 Campaign"),
                "V2", job["platforms"], "complete",
                results=_safe_serialize(job["results"]),
            )

        except Exception as e:
            job["state"] = V2PipelineState.ERROR
            job["error"] = str(e)
            job["events"].put({
                "type": "error", "error": str(e),
                "timestamp": datetime.now().isoformat(),
            })

    thread = threading.Thread(target=execute, daemon=True)
    thread.start()

    return jsonify({"job_id": job_id, "state": V2PipelineState.EXECUTING})


@app.route('/api/v2/campaign/<job_id>/status')
def v2_campaign_status(job_id):
    """V2 ìº í˜ì¸ ìƒíƒœ ì¡°íšŒ."""
    job = v2_jobs.get(job_id)
    if not job:
        return jsonify({"error": "Job not found"}), 404

    return jsonify({
        "job_id": job_id,
        "state": job["state"],
        "coupang_link": job.get("coupang_link"),
        "product_info": job.get("product_info"),
        "draft": job.get("draft"),
        "blog_html": (job.get("blog_html", "") or "")[:500],
        "results": _safe_serialize(job.get("results", {})),
        "error": job.get("error"),
        "created_at": job.get("created_at"),
    })


@app.route('/api/v2/campaign/<job_id>/stream')
def v2_stream(job_id):
    """V2 SSE ìŠ¤íŠ¸ë¦¬ë° â€” 10ë‹¨ê³„ ì§„í–‰ìƒí™©."""
    def generate():
        job = v2_jobs.get(job_id)
        if not job:
            yield f"data: {json.dumps({'type': 'error', 'error': 'Job not found'})}\n\n"
            return

        q = job["events"]
        while job["state"] not in (V2PipelineState.COMPLETE, V2PipelineState.ERROR):
            while not q.empty():
                event = q.get_nowait()
                yield f"data: {json.dumps(event, ensure_ascii=False, default=str)}\n\n"
            time.sleep(0.3)

        # ì”ì—¬ ì´ë²¤íŠ¸ flush
        while not q.empty():
            event = q.get_nowait()
            yield f"data: {json.dumps(event, ensure_ascii=False, default=str)}\n\n"

        # ìµœì¢… ìƒíƒœ
        if job["state"] == V2PipelineState.COMPLETE:
            yield f"data: {json.dumps({'type': 'v2_done', 'results': _safe_serialize(job.get('results', {}))}, ensure_ascii=False, default=str)}\n\n"
        elif job["state"] == V2PipelineState.ERROR:
            yield f"data: {json.dumps({'type': 'error', 'error': job.get('error', 'Unknown error')})}\n\n"

    return Response(generate(), mimetype='text/event-stream',
                    headers={'Cache-Control': 'no-cache', 'X-Accel-Buffering': 'no'})


@app.route('/api/v2/campaign/<job_id>/blog-preview')
def v2_blog_preview(job_id):
    """V2 ë¸”ë¡œê·¸ HTML ë¯¸ë¦¬ë³´ê¸°."""
    job = v2_jobs.get(job_id)
    if not job:
        return jsonify({"error": "Job not found"}), 404

    blog_html = job.get("blog_html", "")
    if blog_html:
        return Response(blog_html, mimetype='text/html; charset=utf-8')
    return jsonify({"error": "ë¸”ë¡œê·¸ HTML ì•„ì§ ìƒì„±ë˜ì§€ ì•ŠìŒ"}), 404


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„œë²„ ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == '__main__':
    import io, sys
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    print("=" * 50)
    print("YJ MCN Automation Dashboard Server")
    print(f"  URL: http://localhost:5001")
    print(f"  Gemini: {'OK' if GEMINI_API_KEY else 'NO'}")
    print(f"  Claude: {'OK' if ANTHROPIC_API_KEY else 'NO'}")
    print(f"  Pexels: {'OK' if PEXELS_API_KEY else 'NO'}")
    print("=" * 50)
    app.run(host='0.0.0.0', port=5001, debug=False, threaded=True)
